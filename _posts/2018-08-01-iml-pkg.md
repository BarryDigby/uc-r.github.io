---
author: Brad Boehmke
layout: post
comments: true
title: Interpreting Machine Learning Models with the iml Package
---

<img src="/public/images/analytics/ML_interpretation/iml_icon.jpg"  style="float:right; margin: 0px 0px 0px 0px; width: 30%; height: 30%;" />

With machine learning interpretability growing in importance, several R packages designed to provide this capability are gaining in popularity. In recent blog posts I assessed [`lime`](http://uc-r.github.io/lime) for model agnostic local interpretability functionality and [`DALEX`](http://uc-r.github.io/dalex) for both local and global machine learning explanation plots.  This [newest tutorial](http://uc-r.github.io/iml-pkg) examines the `iml` package to assess its functionality in providing machine learning interpretability to help you determine if it should become part of your preferred machine learning toolbox.
