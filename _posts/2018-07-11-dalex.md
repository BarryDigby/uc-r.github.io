---
author: Brad Boehmke
layout: post
comments: true
title: Model Interpretability with DALEX
---

<img src="/public/images/analytics/ML_interpretation/dalex_logo.png"  style="float:right; margin: 0px -5px 0px 10px; width: 20%; height: 20%;" />

As advanced machine learning algorithms are gaining acceptance across many organizations and domains, machine learning interpretability is growing in importance to help extract insight and clarity regarding how these algorithms are performing and why one prediction is made over another. There are many methodologies to interpret machine learning results (i.e. variable importance via permutation, partial dependence plots, local interpretable model-agnostic explanations), and many machine learning R packages implement their own versions of one or more methodologies. However, some recent R packages that focus purely on ML interpretability agnostic to any specific ML algorithm are gaining popularity.  One such  package is `DALEX` and this [latest tutorial](http://uc-r.github.io/dalex) covers what this package does (and does not do) so that you can determine if it should become part of your preferred machine learning toolbox.  
